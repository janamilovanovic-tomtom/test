// Copyright (C) 2018 TomTom NV. All rights reserved.
//
// This software is the proprietary copyright of TomTom NV and its subsidiaries and may be
// used for internal evaluation purposes or commercial use strictly subject to separate
// license agreement between you and TomTom NV. If you are the licensee, you are only permitted
// to use this software in accordance with the terms of your license agreement. If you are
// not the licensee, you are not authorized to use this software in any manner and should
// immediately return or destroy it.

= Semi-Stable Instruction IDs

== Status

Rejected

== Context

Links:

*  https://bitbucket.tomtomgroup.com/plugins/servlet/jira-integration/issues/NAV-30067[NAV-30067 API proposal for providing intersection name to clients]
* https://jira.tomtomgroup.com/browse/NAV-21977[NAV-21977 [NIE\] Automated smoke tests in CI of nk2-navigation-instruction-engine]

=== Testing

We would like to productise the crude smoke testing that is currently
being done on one developer desktop machine.  There are two major
purposes of this system:

* Guard against regressions, by highlighting large changes in
  behaviour
* Allow developers to systematically verify changes against real-world
  routes

These goals lead to rather different requirements.

For guarding against regressions, it's important that tests are stable
across map changes.  Otherwise there is a tendency to accept any
changes whenever the map changes, potentially missing serious
regressions.

For verifying intended changes, it's important that old and new
instructions are matched with each other despite quite dramatic
changes in behaviour.  For example if trigger distances are increased
50m, we can expect almost every trigger point to move.  But the system
has to be capable of proving that the trigger distances have moved
50m, no more and no less.

In both of these cases, a key problem is matching instructions (and
triggers) from two different runs of the instruction dumper, despite
potential changes in map and/or code.

Currently we match instructions within a radius of 10m.  This works
well enough when comparing the new instruction engine against the
legacy instruction engine, because even though many instructions don't
match, the data sets are quite different in the first place.  It's
good enough to surface whether the results are getting more or less
similar.  But it isn't really good enough to guard against
regressions, or to verify that changes are having the expected result.

=== Instruction IDs

The Client API asynchronously calls back the client whenever the list
of upcoming instructions changes.  Since we always try to supply a
finite number of upcoming instructions, this list effectively acts as
a sliding window.  Each instruction comes with a unique ID, which
allows clients to easily avoid unnecessarily processing the same
instruction twice.

Until NAV-22470 Instruction IDs were integers that counted up from
zero.  As a first step towards semi-stable IDs, and to prevent clients
misusing these IDs, that was changed to an opaque set of bytes.
Following the example of the routing API, the intention is that these
bytes should actually be an opaque UUID.

== Proposal

We will assign UUIDs to instructions based on a route ID string and the
offset of the instruction along the route.  The offset will be rounded
down so that instructions will usually have the same ID even on
slightly different maps.  The final ID will be a
https://en.wikipedia.org/wiki/Universally_unique_identifier#Versions_3_and_5_(namespace_name-based)[Version 5 UUID],
that is it will consist of a namespace and a hash of the input data.

The route ID string would be opaque to the instruction engine.  In
production this could be a route ID supplied by the routing engine.
In the instruction dumper it could be the route ID taken from the KML
file (e.g. "BERLIN-11").

=== Rounding

The rounding algorithm is the core of this design, that makes the
results semi-stable.  It works by rounding each value down as far as
it can without colliding with the rounded offset of the previous
instruction.

As an example, the following table gives a set of instructions, some
close together and some far apart.  The table also shows a minimum and
maximum of a range.  If the map changes and the instruction has a new
offset anywhere in that range it will keep the same ID, assuming the
other instructions stay where they are.  The result is that in
segments where instructions are close together, they can't move far
without changing ID, as you might expect.  However in segments where
instructions are far apart, those instructions can vary over quite a
wide range and keep the same ID.

[options="header"]
|====
|Offset|Rounded|Minimum|Maximum
|111|0|0|122
|123|100|112|131
|132|130|130|132
|133|133|133|133
|134|134|134|139
|1234|1000|1000|1999
|4321|4000|4000|4321
|4322|4300|4300|4399
|====

The other important case is where instructions are inserted or
removed.  With simple approaches such as an incrementing counter,
every instruction after the change will get a new ID.  It's very hard
to then detect real changes in those later instructions.

With the rounding algorithm, a missing instruction might cause several
following instructions to fail to match, but after a limited distance
the matching will recover.

[options="header"]
|====
|Offset|Rounded|Second Instruction Removed
|1111|0|0
|1234|1000|-
|1413|1400|1000
|1421|1420|1400
|1423|1423|1420
|1499|1490|1490
|1502|1500|1500
|1784|1700|1700
|====

=== Disambiguation

It still may be possible to have multiple instructions with exactly
the same offset.  Therefore the hash must be based on more than just
the offset.  There is no other property of instructions that is stable
across multiple runs of the system, but guaranteed to vary between
instructions in a single run.  Therefore we use an extra
disambiguation integer, a simple counter that starts at zero.
Whenever an offset is the same as or less than the previous one, we
increase the counter, effectively producing a new ID namespace.

[options="header"]
|====
|Offset|Disambiguation|Rounded
|1234|0|0
|2345|0|2000
|2567|0|2500
|2567|1|0
|2578|1|2000
|2570|2|0
|2571|2|2000
|2578|2|2500
|====

This does mean that inserting a new instruction with an identical
offset as an existing instruction will cause all subsequent
instructions to fail to match, since the disambiguation term will be
different from then on.  This is considered acceptable - rare enough
that it doesn't justify extra design work.  The important requirement
is that instruction IDs never repeat within a route.

=== Route ID

Although the purpose of this algorithm is to allow reproducible ID
generation across multiple simulations of the same route, it's
important that instructions from different routes do have
distinct IDs.  Therefore the instruction ID generator should be
initialised with different data for each route.  This term is the
route ID.

For testing purposes, we can define a route either using the origin
and destination coordinates, or using a specified route ID from the
test set.

In production, it would probably be a good idea if even the exact same
origin/destination pair never produces the same instruction IDs.  This
allows truly uniquely identifying instructions from logs.  It also
prevents clients from noticing the reproducibility of instruction IDs
and trying to exploit that undocumented feature somehow.  This can be
achieved by generating another UUID (version 1, 2 or 4) and using that
to initialise the ID generation.

If we log the route ID, we will be able to reproduce an exact sequence
of instruction IDs even from a production system.  This could well be
useful as we develop and verify a fix to a user bug report, to allow
us to cleanly compare the behaviour of different implementations to
the observed production data.

=== Initialisation sequence

The namespaces of namespace-based UUIDs are required to be UUIDs themselves, not strings.  So generation looks like "NSUUID + string => UUID".  Therefore there is a blockchain-like sequence of operations to get the actual Instruction IDs:

1. Generate zero UUID
2. zero UUID + Route ID => NSUUID
3. NSUUID + route offset + disambiguation => Instruction UUID

== Decision

We will not do any of this.

This brings a significant amount of complexity into our deliverable code, when the only compelling use case is our own internal testing.

Instead we can use "real" globally unique UUIDs.  To generate reference data we can redact any unstable data such as instruction IDs.  If desired, we can implement semi-stable replacement IDs using python scripts.

== Consequences

* Our deliverable code will be pretty simple and explainable
* Reference data will be post-processed before committing to a repository
